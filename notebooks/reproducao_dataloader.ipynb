{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.baseline import CODE, CODEsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "832it [00:00, 8312.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking exam_id consistency in idx dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "273026it [00:32, 8330.61it/s]\n",
      "1634it [00:00, 8166.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking exam_id consistency in idx dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23430it [00:02, 8221.26it/s]\n",
      "1665it [00:00, 8322.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking exam_id consistency in idx dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11184it [00:01, 8306.08it/s]\n"
     ]
    }
   ],
   "source": [
    "database = CODE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = CODEsplit(database, database.trn_idx_dict)\n",
    "val_ds = CODEsplit(database, database.val_idx_dict)\n",
    "tst_ds = CODEsplit(database, database.tst_idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "trn_loader = torch.utils.data.DataLoader(trn_ds, batch_size = 128,\n",
    "                                          shuffle = True, num_workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2134/2134 [46:35<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for batch in tqdm(trn_loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = '/home/josegfer/code/code14/code14.h5'\n",
    "metadata_path = '/home/josegfer/code/code14/exams.csv'\n",
    "reports_csv_path = '/home/josegfer/code/code14/BioBERTpt_text_report_crop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "val_size = 0.10\n",
    "tst_size = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id_col = 'patient_id'\n",
    "exam_id_col = 'exam_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CODE():\n",
    "    def __init__(self, hdf5_path, metadata_path, val_size, tst_size):\n",
    "        self.hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "        self.metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "        self.val_size = val_size\n",
    "        self.tst_size = tst_size\n",
    "\n",
    "        trn_metadata, val_metadata, tst_metadata = self.split()\n",
    "        self.check_dataleakage(trn_metadata, val_metadata, tst_metadata)\n",
    "        \n",
    "        self.trn_idx_dict = self.get_idx_dict(trn_metadata)\n",
    "        self.val_idx_dict = self.get_idx_dict(val_metadata)\n",
    "        self.tst_idx_dict = self.get_idx_dict(tst_metadata)\n",
    "\n",
    "    def split(self, patient_id_col = 'patient_id'):\n",
    "        patient_ids = self.metadata[patient_id_col].unique()\n",
    "\n",
    "        num_trn = int(len(patient_ids) * (1 - self.tst_size - self.val_size))\n",
    "        num_val = int(len(patient_ids) * self.val_size)\n",
    "\n",
    "        trn_ids = set(patient_ids[:num_trn])\n",
    "        val_ids = set(patient_ids[num_trn : num_trn + num_val])\n",
    "        tst_ids = set(patient_ids[num_trn + num_val :])\n",
    "\n",
    "        trn_metadata = self.metadata.loc[self.metadata[patient_id_col].isin(trn_ids)]\n",
    "        val_metadata = self.metadata.loc[self.metadata[patient_id_col].isin(val_ids)]\n",
    "        tst_metadata = self.metadata.loc[self.metadata[patient_id_col].isin(tst_ids)]\n",
    "\n",
    "        return trn_metadata, val_metadata, tst_metadata\n",
    "    \n",
    "    def check_dataleakage(self, trn_metadata, val_metadata, tst_metadata, exam_id_col = 'exam_id'):\n",
    "        trn_ids = set(trn_metadata[exam_id_col].unique())\n",
    "        val_ids = set(val_metadata[exam_id_col].unique())\n",
    "        tst_ids = set(tst_metadata[exam_id_col].unique())\n",
    "        assert (len(trn_ids.intersection(val_ids)) == 0), \"Some IDs are present in both train and validation sets.\"\n",
    "        assert (len(trn_ids.intersection(tst_ids)) == 0), \"Some IDs are present in both train and test sets.\"\n",
    "        assert (len(val_ids.intersection(tst_ids)) == 0), \"Some IDs are present in both validation and test sets.\"\n",
    "\n",
    "    def get_idx_dict(self, split_metadata, exam_id_col = 'exam_id'):\n",
    "        split_exams, split_h5_idx, temp = np.intersect1d(self.hdf5_file[exam_id_col], split_metadata[exam_id_col].values, return_indices = True)\n",
    "        split_csv_idx = split_metadata.iloc[temp].index.values\n",
    "        split_idx_dict = {exam_id_col: split_exams, 'h5_idx': split_h5_idx, 'csv_idx': split_csv_idx}\n",
    "\n",
    "        print('checking exam_id consistency in idx dict')\n",
    "        for idx, exam_id in tqdm(enumerate(split_idx_dict[exam_id_col])):\n",
    "            assert self.hdf5_file[exam_id_col][split_idx_dict['h5_idx'][idx]] == exam_id\n",
    "            assert self.metadata[exam_id_col][split_idx_dict['csv_idx'][idx]] == exam_id\n",
    "        return split_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "804it [00:00, 8036.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking exam_id consistency in idx dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "273026it [00:33, 8110.67it/s]\n",
      "817it [00:00, 8161.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking exam_id consistency in idx dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23430it [00:02, 8248.85it/s]\n",
      "812it [00:00, 8112.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking exam_id consistency in idx dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11184it [00:01, 8150.12it/s]\n"
     ]
    }
   ],
   "source": [
    "data = CODE(hdf5_path, metadata_path, val_size, tst_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx_dict = data.trn_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273026, 273026, 273026)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_idx_dict['exam_id']), len(split_idx_dict['h5_idx']), len(split_idx_dict['csv_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590673,\n",
       " array([[-4.87810344e-01, -2.66771287e-01,  2.21039057e-01, ...,\n",
       "         -1.17379367e+00, -5.56408703e-01, -4.87810344e-01],\n",
       "        [-4.81065780e-01, -2.60196328e-01,  2.20869452e-01, ...,\n",
       "         -1.16749966e+00, -5.51513910e-01, -4.82329220e-01],\n",
       "        [-4.79793221e-01, -2.57917106e-01,  2.21876070e-01, ...,\n",
       "         -1.15992427e+00, -5.42299151e-01, -4.77297604e-01],\n",
       "        ...,\n",
       "        [-1.37249243e+00, -1.28117001e+00,  9.13222730e-02, ...,\n",
       "         -8.78245056e-01, -5.03962398e-01,  8.59386753e-04],\n",
       "        [-1.36670578e+00, -1.27589798e+00,  9.08078253e-02, ...,\n",
       "         -8.68614078e-01, -4.97095346e-01,  1.69357355e-03],\n",
       "        [-1.36146402e+00, -1.26946747e+00,  9.19967964e-02, ...,\n",
       "         -8.57375383e-01, -4.82351691e-01,  1.05662365e-02]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.hdf5_file['exam_id'][0], data.hdf5_file['tracings'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1169160"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metadata['exam_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70599"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.trn_idx_dict['csv_idx'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False,  True, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [False, False, False,  True, False, False]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metadata[[\"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"AF\", \"ST\"]].loc[data.trn_idx_dict['csv_idx'][0:3]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CODEsplit(Dataset):\n",
    "    def __init__(self, database, split_idx_dict, \n",
    "                 tracing_col = 'tracings', exam_id_col = 'exam_id', output_col = [\"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"AF\", \"ST\"]):\n",
    "        self.database = database\n",
    "        self.split_idx_dict = split_idx_dict\n",
    "\n",
    "        self.tracing_col = tracing_col\n",
    "        self.exam_id_col = exam_id_col\n",
    "        self.output_col = output_col\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.split_idx_dict[exam_id_col])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {'X': self.database.hdf5_file[self.tracing_col][self.split_idx_dict['h5_idx'][idx]], \n",
    "                'y': self.database.metadata[self.output_col].loc[self.split_idx_dict['csv_idx'][idx]].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = CODEsplit(data, data.trn_idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = torch.utils.data.DataLoader(trn_ds, batch_size = 128,\n",
    "                                          shuffle = True, num_workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2134 [00:13<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(trn_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "reports = h5py.File(reports_csv_path, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = metadata[patient_id_col].unique()\n",
    "\n",
    "num_trn = int(len(patient_ids) * (1 - tst_size - val_size))\n",
    "num_val = int(len(patient_ids) * val_size)\n",
    "\n",
    "trn_ids = set(patient_ids[:num_trn])\n",
    "val_ids = set(patient_ids[num_trn : num_trn + num_val])\n",
    "tst_ids = set(patient_ids[num_trn + num_val :])\n",
    "\n",
    "trn_metadata = metadata.loc[metadata[patient_id_col].isin(trn_ids)]\n",
    "val_metadata = metadata.loc[metadata[patient_id_col].isin(val_ids)]\n",
    "tst_metadata = metadata.loc[metadata[patient_id_col].isin(tst_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ids = set(trn_metadata[exam_id_col].unique())\n",
    "val_ids = set(val_metadata[exam_id_col].unique())\n",
    "tst_ids = set(tst_metadata[exam_id_col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(trn_ids.intersection(val_ids)) == 0), \"Some IDs are present in both train and validation sets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(trn_ids.intersection(tst_ids)) == 0), \"Some IDs are present in both train and test sets.\"\n",
    "assert (len(val_ids.intersection(tst_ids)) == 0), \"Some IDs are present in both validation and test sets.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_exams, trn_h5_idx, temp = np.intersect1d(hdf5_file['exam_id'], trn_metadata['exam_id'].values, return_indices = True)\n",
    "trn_csv_idx = trn_metadata.iloc[temp].index.values\n",
    "trn_idx_dict = {'exam_id': trn_exams, 'h5_idx': trn_h5_idx, 'csv_idx': trn_csv_idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273026, 273026, 273026)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_idx_dict['exam_id']), len(trn_idx_dict['h5_idx']), len(trn_idx_dict['csv_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "868it [00:00, 8671.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking exam_id consistency in idx dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "273026it [00:29, 9365.08it/s] \n"
     ]
    }
   ],
   "source": [
    "print('checking exam_id consistency in idx dict')\n",
    "for idx, exam_id in tqdm(enumerate(trn_idx_dict['exam_id'])):\n",
    "    assert hdf5_file[exam_id_col][trn_idx_dict['h5_idx'][idx]] == exam_id\n",
    "    assert metadata[exam_id_col][trn_idx_dict['csv_idx'][idx]] == exam_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
